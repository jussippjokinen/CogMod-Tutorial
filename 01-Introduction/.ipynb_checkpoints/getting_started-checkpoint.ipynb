{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cardiovascular-breed",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/howesa/CHI22-CogMod-Tutorial/blob/main/getting_started.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-lloyd",
   "metadata": {},
   "source": [
    "# C28: Cognitive Modelling: From GOMS to Deep Reinforcement Learning\n",
    "\n",
    "\n",
    "Scheduled: 9am-6pm April 26\n",
    "\n",
    "Organizers:\n",
    "\n",
    "Jussi P. P. Jokinen, University of Jyväskylä<br>\n",
    "Antti Oulasvirta, Aalto University<br>\n",
    "Andrew Howes, University of Birmingham\n",
    "\n",
    "Contact email: jussi.p.p.jokinen@jyu.fi\n",
    "\n",
    "https://chi2023.acm.org/for-authors/learning/courses/accepted-courses/\n",
    "\n",
    "This course introduces computational cognitive modeling for researchers and practitioners in the field of HCI. Cognitive models use computer programs to model how users perceive, think, and act in interactive tasks. They offer a powerful approach for understanding interaction and improving user interfaces. The course starts with a review of classic models such as Fitts's Law, GOMS and ACT-R. It builds on this review to provide an introduction to modern modelling approaches powered by machine learning methods, in particular deep learning, reinforcement learning (RL), and deep RL. The course is built around hands-on Python programming using Colab notebooks.\n",
    "\n",
    "A basic understanding of programming concepts is a prerequisite for the course and some familiarity with Python and Google Colab Notebooks (similar to Jupyter notebooks) is likely to be useful. Hopefully, you are reading this text having uploaded it to your private Google Colab -- if not then click on the \"Open in Colab\" link at the top of this page. This is a good start and it means that the document you are reading is not a static web page but, instead, an interactive environment. The key property of this environment is that it lets you write and execute code interactively. \n",
    "\n",
    "We will illustrate interactive code execution later in this notebook. We will also briefly review some of the historically important ideas in cognitive modelling for HCI. However, before we do that, we first state the learning objectives of the course and also propose a set of scientific objectives for a modern approach to cognitive modeling -- an approach that takes full advantage of recent advances in machine learning. The scientific objectives will be cruical to understanding the modeling approaches and techniques introduced later in the course. They will also be used as a basis for critiquing the historically important approaches from GOMS to ACT-R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-ghost",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "\n",
    "The learning objectives for the course are of two types, either \"understand...\" or \"be able to...\", where the latter is a practical skill. The objectives are grouped according to the three main modules of the course.\n",
    "\n",
    "* Understand the strengths and weaknesses of a cognitive model specified as a Partially Observable Markov Decision Process (POMDP) with foveated vision and Kalman state estimation.\n",
    "* Be able to use a Python reinforcement learning library -- running on a Colab server -- to find a solution to this POMDP.\n",
    "* Be able to test the above model under a range of conditions and generate results for comparison to human data.\n",
    "* Understand the HCI cognitive modelling problems for which RL is useful.\n",
    "\n",
    "\n",
    "* Understand the strengths and weaknesses of a cognitive model specified as an Artificial Neural Network (ANN).\n",
    "* Be able to make use of well-known pre-trained ANNs by incorporating Python libraries in your models.\n",
    "* Understand the HCI cognitive modelling problems for which ANNs are useful.\n",
    "\n",
    "\n",
    "* Understand modeling workflow, with an ability to provide a detailed case example.\n",
    "* Be able to use a reinforcement learning model of multitasking while driving.\n",
    "* Be able to use Bayesian likelihood free inference to fit model parameters.\n",
    "* Understand how parameterised simulation models can be used to explore design candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-robinson",
   "metadata": {},
   "source": [
    "## Criteria for a modern approach to cognitive modeling\n",
    "\n",
    "While the tutorial seeks to cover a wide range of modeling techniques it is unashamedly committed to an emergent approach in cognitive science that is both routed in the history of information processing psychology and which seeks to take advantage of the recent convergence of cognitive science and HCI. Accordingly, the tutorial works towards introducing the student to modelling techniques which meet the following criteria:\n",
    "\n",
    "* Be firmly grounded in the <strong>information processing</strong> view of cognition (Miller, 1956).\n",
    "* Explain the <strong>adaptation</strong> of human behaviour to the environment (including the designed environment) (Brunswick, 1943). Brunswik proposed that humans be explained in terms of statistical descriptions of the structure of the environment. In HCI, models ought to be tested on tasks that are representative of the environment that computer users inhabit.\n",
    "* Build on Simon's (1955) insight that adaptation is <strong>bounded</strong> by two sources of constraint; not only those on  on the environment, but also constraints on the mind, including perceptual/motor and memory constraints.\n",
    "* Clearly distinguish the explanatory role of invariant bounds on the mind, such as memory limits and visual acuity, from the <strong>strategies</strong> that are learned through experience, for example rehersal or knowing where to look for important information when a web page is opened. While people are bounded, much of what computer users do is strategic (Oulasvirta, et al., 2022).\n",
    "* Formally define theories of cognition as <strong>optimisation</strong> problems that incorporate bounds on both the environment and cognition (Lewis, Howes, Singh, 2014; Lieder, Griffiths, 2020). Human-like strategies can then be predicted by solving such optimisation problems.\n",
    "* Make use of the convergence between <strong>machine learning</strong> and cognitive science  (Gershman, Tenenbaum and Horvitz, 2015), both to specify theories of the bounds on cognition and to derive the strategies that are a response to these bounds. Machine learning has the potential to add both rigour and convenience to the process of cognitive modeling in HCI.\n",
    "* Test theories of cognition using <strong>inverse modeling</strong> (Kangasrääsiö, et al., 2019).\n",
    "\n",
    "These are a challenging set of criteria that are not met in their entirety by any single cognitive model. However, they point in a direction for the future and can be used as a basis of understanding the relative stengths and weaknesses of each existing approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-guess",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This section shows you how to interact with the notebooks.\n",
    "\n",
    "**Fitts's Law**\n",
    "\n",
    "Below find a short Python script -- in a code cell -- that computes a predicted movement time MT given the distance D and width W of a button on a screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "a = 1.03\n",
    "b = 0.096\n",
    "D = 8\n",
    "W = 1.25\n",
    "\n",
    "MT = a + b * log2(0.5+D/W)\n",
    "MT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-pastor",
   "metadata": {},
   "source": [
    "You can execute the code in the above cell by selecting it with a click and then pressing the play button to the left of the code, or by using the keyboard shortcut 'Command/Ctrl+Enter'. \n",
    "\n",
    "To edit the code, click the cell and start typing. For example, you can predict MT for a different distance by changing the value of D and re-running the cell. Try it now.\n",
    "\n",
    "Some readers may recognise the above formula as <strong>Fitts's Law</strong>, but whether you recognise it or not, you have have now used Python and Colab to execute your first model of a user. Congratulations, you are on the path to mastery!\n",
    "\n",
    "Fitts's Law illustrates one key property of models of users in HCI which is that they make <strong>predictions</strong>. If parameters 'a' and 'b' are known then Fitts's Law can be used to predict movement time given the distance and width of a target. For now, lets continue to learn about Colab's notebooks and Python. One important thing to know is that variables that you define in one cell can be used in other cells. For example, the value of MT is available in the code cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "MT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-harvest",
   "metadata": {},
   "source": [
    "Code cells can also be used to define Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitts_mt(D,W):\n",
    "    a = 1.03\n",
    "    b = 0.096\n",
    "    MT = a + b * log2(0.5+D/W)\n",
    "    return MT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-investigation",
   "metadata": {},
   "source": [
    "Run the code cell above to define the function. Once the function is defined, we can call it from other code cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitts_mt(2,1.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-practice",
   "metadata": {},
   "source": [
    "Another important feature of Colab notebooks is that they can be used to visualise data. In the code cell below our fitts_mt() function is used to visualise the relationship between MT and distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-lesson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "xs = [x for x in range(1,17)]\n",
    "ys = [fitts_mt(x,1.25) for x in xs]\n",
    "\n",
    "plt.plot(xs, ys, '-')\n",
    "plt.xlabel(\"Distance D\")\n",
    "plt.ylabel(\"Movement time MT\")\n",
    "plt.title(\"Fitts's Law\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-stupid",
   "metadata": {},
   "source": [
    "You may have noticed the use of the Python import statement in the above code cells. As their name suggests these import code from libraries. There are many basic libraries in python that are used for maths and plotting, for example. More exciting are the libraries that support machine learning. We will see as the tutorial progresses that these libraries can be very useful for modeling cognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-authorization",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"warning\" style='padding:0.1em; background-color:#E9D8FD; color:#69337A'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b>Reflection</b></p>\n",
    "<p style='margin-left:1em;'>Fitts's Law has proved highly influential in HCI since it was used by Card, English and Burr (1978) to compare various input devices. There are many research papers that describe more recent developments, the application of Fitts's Law, and a number of limitations. One limitation is the fact that the law says nothing about speed/accuracy trade-offs, nor anything about errors; thereby failing to meet the demand for explaining <strong>adaptation</strong> in our above criteria for modelling. When a person moves a pointer to a target, they can choose whether to move quickly or slowly. If they choose to move quickly then the chance that they will make an error will increase. This is a topic that we will return to later in the tutorial when we look at reinforcement learning models of cognition. In these models, a reward function determines the desired speed/accuracy trade-off function and predictions of movement time emerge through learning an optimal policy for the reward function. The ability to model speed/accuracy trade-offs is critical to the scientific understanding of HCI because of the adaptive nature of human cognition.\n",
    "<p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-calculator",
   "metadata": {},
   "source": [
    "**GOMS**\n",
    "\n",
    "GOMS was an approach to cognitive modeling in Human-Computer Interaction in which human skill for computing systems was represented in terms of goals, operators, methods and selection rules. Many other methods for modeling task knowledge were based on similar concepts and GOMS gave rise to many variants through the 1980s and into the 2000s. Though their meanings have been refined, some GOMS concepts remain useful today, and it is worth briefly reviewing them. \n",
    "\n",
    "Goals are what the user has to accomplish and represent the end towards which the user is directed. Example goals might include making a set of changes to a text document or replying to an email.  Goals typically have subgoals giving rise to the hierarchical structure of skill. For example, the goal of correcting the typos in a text might have as subgoals to \"delete text\" and \"insert word\". \n",
    "\n",
    "Operators model what a user can do in service of a goal. Operators may be theories of how a user makes changes to the external environment or they may be theories of mental operators that, for example, update memory. The very lowest level of operator could be indiviudal muscle axon innervations but cognitive models typically define operators at a much higher level than this. For example, a cognitive model of form filling might define operators at the word entry level, whereas a cognitive model of typing might define operators at a character level. \n",
    "\n",
    "Methods are sequences of subgoals and operators that achieve specific goals. For example, the goal of entering a name into a form might be accomplished with methods that we can represent with Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_name():\n",
    "    move_caret_to_location()\n",
    "    print(\"ENTER NAME\")\n",
    "\n",
    "def move_caret_to_location():\n",
    "    print(\"DETECT LOCATION\")\n",
    "    print(\"MOVE MOUSE UNTIL POINTER AT LOCATION\")\n",
    "    print(\"CLICK MOUSE\")\n",
    "\n",
    "enter_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-stanford",
   "metadata": {},
   "source": [
    "When the code cell above is executed, the GOMS methods for the goal ENTER NAME are expanded resulting in the required operator sequence being printed.\n",
    "\n",
    "Selection Rules choose between different methods for achieving a goal. For example, an alternative method for ENTER NAME might use TAB to move the caret from an earlier location rather than using the mouse. The selection rule might prefer one method or the other depending on the sequentiality of the entry process.\n",
    "\n",
    "The difference between a goal and an operator in GOMS is that operators are not broken down any further; they are at the bottom of a hierarchy of subgoals. Card, Moran and Newell demonstrated GOMS models at 4 levels of analysis. At one level the operators represented tasks taking about 30 seconds, at another the operators represented single keystrokes. As with Fitts's Law, the idea was that GOMS could be used to predict human performance time by adding up the durations of the sequence of operators required to achieve a goal. \n",
    "\n",
    "<p>\n",
    "<div class=\"warning\" style='padding:0.1em; background-color:#E9D8FD; color:#69337A'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b>Reflection</b></p>\n",
    "<p style='margin-left:1em;'>GOMS embodied a number of concepts tha remain important to modeling today. These include the idea that human task knowledge is hierarchical and that goals are decomposed into subgoals and eventually operators. This ideas echoes in modern ideas concerning hierarchical reinforcement learning, for example.\n",
    "\n",
    "<p style='margin-left:1em;'>But, there are a number of concepts missing in GOMS that are crucial to modern analyses of task knowledge. One of these concepts is that of utility (or reward). Another is the extent to which task knowledge is now known to  be conditioned on state; that is on bottom-up information and not just on top-down hierarchical control. Cognition is embodied and interactive. GOMS therefore fails to meet the demand of our criteria; cognitive models must be sensitive to the statistical structure of the task environment; in other words the ecology.\n",
    "    \n",
    "<p style='margin-left:1em;'>In addition, GOMS models are difficult to build because they demand that the analyst hand-code a set of rules that represent a user's task knowledge -- which can require many interlated rules and be difficult to determine from human behaviour. GOMS, therefore, fails to meet our demand that cognitive modeling approaches should take full advantage of the recent convergence between ML and cognitive science. This convergence provides methods for learning task knowledge that, in for some tasks, results in human-level performance.\n",
    "<p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-productivity",
   "metadata": {},
   "source": [
    "**Cognitive architectures**\n",
    "\n",
    "Cognitive architectures, particuarly ACT-R (Anderson, 2007) and EPIC (Kieras and Meyer, 1997), have played a crucial role in cognitive modeling for HCI. \n",
    "\n",
    "ACT-R consists of a number of integrated modules for modeling cognition. The modules include those for audition, vision, manual movement, declarative memory, and temporal memory. These modules are motivated by neuroscientific and behavioural evidence and empirically validated by many hundreds of human experiments. The modules are coordinated by a central production module which is responsible for matching, selecting and executing production rules. These rules make changes to the state of the other modules by, for example, issuing motor commands, or updating memories. ACT-R also provides theories of learning. In ACT-R's theory of procedural learning, skills are acquired by recruiting past problem solutions while solving new problems, thereby providing a theory of learning by doing and learning by example (Anderson and Schunn, 2000). ACT-R also models activation learning in declarative memory. Two factors influence this learning: how many times an item in memory was needed in the past, and how recently it was needed. The activation learning rule is derived from Bayesian statistics. ACT-R uses activation values of items in memory to order the chunks in the matching process.\n",
    "\n",
    "\n",
    "<p>\n",
    "<div class=\"warning\" style='padding:0.1em; background-color:#E9D8FD; color:#69337A'>\n",
    "<span>\n",
    "<p style='margin-top:1em; text-align:center'>\n",
    "<b>Reflection</b></p>\n",
    "<p style='margin-left:1em;'>One of the most significant theoretical contributions to HCI, information foraging theory, was grounded in ACT-R theory (Pirolli, 1997). EPIC has also played a significant role, for example, in models of visual search (Kieras and Hornoff, 2014). Arguably, ACT-R represents the state of the art in computational models of human memory.\n",
    "\n",
    "<p style='margin-left:1em;'>ACT-R and EPIC meet many of the criteria for cognitive modeling that we set at the beginning of this notebook. They are both bounded information processing theories of cognition and they embrace the notion of adaptation. In ACT-R's case adaptation is modelled through various learning mechanisms built into the architecture. These can both be used to generate multiple strategies and to select between them, meeting another criteria. However, ACT-R and EPIC do not permit the definition of theories of cognition as optimisation problems in response to which modern machine learning algorithms can be used to automatically find human-like strategies. Instead, even with learning researchers are still required to program some production rules, considerably increasing the burden on the modeler, and also increasing the parametric flexibility of the model leading to difficulties associated with fitting ACT-R models to data.\n",
    "    \n",
    "<p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-congress",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "You are now at the end of the \"getting started\" module of the CHI'2023 course on cognitive modeling. Well done, for getting this far. \n",
    "\n",
    "We have attempted to cover over 40 years of cognitive modeling in HCI in a few hundred words; as a consequence we are aware of many many omissions. However, our main purpose was to illustrate the contrast between the well-known approaches in HCI and the modern -- machine learning fuelled -- approach that has been emerging over the past few years. This new approach, sometimes known as computational rationality (or resource rationality), begins to meet all of the criteria for cognitive modeling that we articulated at the beginnig of this document. Accordingly, the main body of the tutorial will pick up on these criteria to motivate the use deep learning and deep reinforcement learning in cognitive models for HCI.\n",
    "\n",
    "If you have time to find out more then recommended, and highly recommended papers, are starred and double starred in the bibliogrpahy below. To find out more about Colab notebooks, see <a href=\"/notebooks/basic_features_overview.ipynb\">Overview of Colab</a>. Colab notebooks are Jupyter notebooks that are hosted by Colab. To find out more about the Jupyter project, see <a href=\"https://www.jupyter.org\">jupyter.org</a>.\n",
    "\n",
    "If you are a novice Python programmer then you should find out more about lists, dictionaries and about classes/objects.\n",
    "\n",
    "Further modules will be provided on the day of the tutorial. We look forward to seeing you there.\n",
    "\n",
    "Jussi Jokinen<br>\n",
    "Antti Oulasvirta<br>\n",
    "Andrew Howes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-vehicle",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Anderson, J. R. (2007). How Can the Human Mind Exist in the Physical Universe? Oxford University Press.\n",
    "\n",
    "Card, S. M., & Newell, T. (1983). A.(1983)“The Psychology of Human-Computer Interaction.”.\n",
    "\n",
    "Card, S. K., English, W. K., Burr, B. J., 1978. Evaluation of mouse, rate controlled isometric joystick, step keys and text keys for text selection on a CRT. Ergonomics 21, 601-613.\n",
    "\n",
    "\\* Gershman, S. J., Horvitz, E. J., & Tenenbaum, J. B. (2015). Computational rationality: A converging paradigm for intelligence in brains, minds, and machines. Science, 349(6245), 273-278.\n",
    "\n",
    "John, B. E., & Kieras, D. E. (1996). The GOMS family of user interface analysis techniques: Comparison and contrast. ACM Transactions on Computer-Human Interaction (TOCHI), 3(4), 320-351.\n",
    "\n",
    "\\* Kangasrääsiö, A., Jokinen, J. P., Oulasvirta, A., Howes, A., & Kaski, S. (2019). Parameter inference for computational cognitive models with Approximate Bayesian Computation. Cognitive science, 43(6), e12738.\n",
    "\n",
    "Kieras, D. E., & Meyer, D. E. (1997). An overview of the EPIC architecture for cognition and performance with application to human-computer interaction. Human–Computer Interaction, 12(4), 391-438.\n",
    "\n",
    "Kieras, D. E., & Hornof, A. J. (2014, April). Towards accurate and practical predictive models of active-vision-based visual search. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 3875-3884).\n",
    "\n",
    "** Lewis, R. L., Howes, A., & Singh, S. (2014). Computational rationality: Linking mechanism and behavior through bounded utility maximization. Topics in cognitive science, 6(2), 279-311.\n",
    "\n",
    "** Lieder, F., & Griffiths, T. L. (2020). Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources. Behavioral and Brain Sciences, 43.\n",
    "\n",
    "Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological review, 63(2), 81.\n",
    "\n",
    "\\* Pirolli, P. (1997). Computational models of information scent-following in a very large browsable text collection. In Proceedings of the ACM SIGCHI Conference on Human factors in computing systems (pp. 3-10).\n",
    "\n",
    "Simon, H. A. (1955). A behavioral model of rational choice. The quarterly journal of economics, 69(1), 99-118.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
